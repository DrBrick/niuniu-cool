<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hive on ฅ՞•ﻌ•՞ฅ要抱抱</title>
    <link>https://niub.link/tags/hive/</link>
    <description>Recent content in Hive on ฅ՞•ﻌ•՞ฅ要抱抱</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>牛牛ฅ^•ﻌ•^ฅ</copyright>
    <lastBuildDate>Mon, 05 Oct 2020 21:12:17 +0800</lastBuildDate><atom:link href="https://niub.link/tags/hive/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>关于Hive和YARNの读书笔记</title>
      <link>https://niub.link/posts/helloyarn/</link>
      <pubDate>Mon, 05 Oct 2020 21:12:17 +0800</pubDate>
      
      <guid>https://niub.link/posts/helloyarn/</guid>
      <description>一、回顾Hive的架构 1.1 Hive的基本结构 在Hadoop 2.x版本以后，Hive所有运行的任务都是交由YARN来统一管理。下图所示为Hive作业的工作流程：
客户端提交SQL作业到HiveServer2, HiveServer2会根据用户提交的SQL作业及数据库中现有的元数据信息（实际生产中存放在MySQL中）生成一份可供计算引擎执行的计划。每个执行计划对应若干MapReduce作业，Hive会将所有的MapReduce作业都一一提交到YARN中，由YARN去负责创建MapReduce作业对应的子任务任务，并协调它们的运行。YARN创建的子任务会与HDFS进行交互，获取计算所需的数据，计算完成后将最终的结果写入HDFS或者本地。
从整个Hive运行作业的过程我们可以知道Hive自身主要包含3个部分：
 第一部分是客户端（Client） 第二部分是HiveServer2 第三部分是元数据以及元数据服务。  1.2 关于Hive的元数据 Hive的元数据保存在Hive的metastore数据中，里面记录着Hive数据库、表、分区和列的一些当前状态信息，通过收集这些状态信息，可以帮助我们更好地监控Hive 数据库当前的状态，提前感知可能存在的问题；可以帮助基于成本代价的SQL 查询优化，做更为正确的自动优化操作。
Hive的元数据主要分为5个大部分：
 数据库相关的元数据 表相关的元数据 分区相关的元数据 文件存储相关的元数据 其他（事务信息、锁信息以及权限相关信息）  1.3 Hive的知识体系 下面一张图摘自《Hive性能调优实战》，全面的展示了Hive的知识体系，其实这篇文章算是我阅读这本书的读书笔记吧，很多知识点讲的比较详细我就直接摘抄下来了。
二、YARN详解 2.1 传统多线程编程和调度框架的对比 在单机程序设计中， 为了快速处理一个大的数据集， 通常采用多线程并行编程。大体流程如下 ： 先由操作系统启动一个主线程， 由它负责数据切分、 任务分配、 子线程启动和销毁等工作， 而各个子线程只负责计算自己的数据， 当所有子线程处理完数据后， 主线程再退出。
而，在生产环境中的大数据集群，所有作业或系统运行所需的资源，都不是直接向操作系统申请，而是交由资源管理器和调度框架代为申请。每个作业或系统所需的资源都是由资源管理和调度框架统一分配、协调。在业界中扮演这一角色的组件有YARN、Mesos等。
2.2 YARN的优点 YARN作为资源调用框架有着如下优点：
 提高系统的资源利用率。不同系统和不同业务在不同的时间点对硬件资源的需求是不一样的，例如一些离线业务通常在凌晨时间启动，除了这个阶段的离线业务对资源的占用比较高，其他时间段基本是空闲的，通过统一资源调度和协调，将这些时间段的资源分配给其他系统。不仅计算资源可以共享，由于允许多套系统部署在一个集群，也能增加系统存储资源的利用率。 协调不同作业/不同系统的资源，减少不同作业和不同系统之间的资源争抢。例如通过资源管理和调度框架并通过一定的资源分配策略，能够保证在多作业情况下，各个作业都能够得到足够的资源得以运行，而不会出现一个作业占用所有资源，导致其他作业全部阻塞的情况。 增强系统扩展性。资源管理和调度框架，允许硬件资源的动态伸缩，而不会影响作业的运行。 资源调度与管理工具把控着资源的分配和任务的调度，直接影响程序的运行效率。如果任务得到资源少了，必将影响自身的程序运行效率，如果任务占用过多资源，在集群任务运行高峰期，必然导致挤占其他任务运行所需的资源。  那么如何利用资源与调度管理工具？作为大数据集群的使用者，基于Hive 做业务的开发者要高效地利用资源与调度管理工具，需要知道两方面的内容：
 YARN运行的基本组成和工作原理，能够基本理清程序运行的整体流程，知道哪些过程或者配置可能成为瓶颈，可以先不用了解，但一定要有意识。 YARN资源调度与分配算法。   这里有个感触就是，对学习任何一个大数据组件是不是也应该采用这种方式呢？第一要熟悉该组件的基本组成和工作原理，对其大体的工作流程要熟悉。当然了看一遍是不可能全部记住以及全部消化和理解的。不如多看几遍，很多陌生的名词头一次看或许印象不深，但是如果多看几遍甚至发到技术群讨论一下，印象和理解或许更加深刻，也有助于对该技术组件的学习。
由此引申HDFS、MapReduce、Kafka、HBase、Spark、Flink&amp;hellip;都按照这种套路来学，会不会有触类旁通的效果呢？
 2.3 YARN的基本组成 YARN的基本结构由一个ResourceManager与多个NodeManager组成。ResourceManager负责对NodeManager所持有的资源进行统一管理和调度。当在处理一个作业时ResourceManager会在NodeManager所在节点创建一全权负责单个作业运行和监控的程序ApplicationMaster。
  ResouceManager（简称RM）
 资源管理器负责整个集群资源的调度，该组件由两部分构成：调度器（Scheduler）和ApplicationsMaster（简称ASM）。调度器会根据特定调度器实现调度算法，结合作业所在的队列资源容量，将资源按调度算法分配给每个任务。分配的资源将用容器（container）形式提供，容器是一个相对封闭独立的环境，已经将CPU、内存及任务运行所需环境条件封装在一起。通过容器可以很好地限定每个任务使用的资源量。YARN调度器目前在生产环境中被用得较多的有两种：能力调度器（CapacityScheduler）和公平调度器（Fair Scheduler）。（还有一种FIFO Scheduler）</description>
    </item>
    
    <item>
      <title>再来一道SQL题</title>
      <link>https://niub.link/posts/keep-water-for-hive/</link>
      <pubDate>Sun, 04 Oct 2020 21:37:37 +0800</pubDate>
      
      <guid>https://niub.link/posts/keep-water-for-hive/</guid>
      <description>一、求每一年最高气温的那一天以及温度 1.1 数据准备 2014010114 2014010216 2014010317 2014010410 2014010506 2012010609 2012010732 2012010812 2012010919 2012011023 2001010116 2001010212 2001010310 2001010411 2001010529 2013010619 2013010722 2013010812 2013010929 2013011023 2008010105 2008010216 2008010337 2008010414 2008010516 2007010619 2007010712 2007010812 2007010999 2007011023 2010010114 2010010216 2010010317 2010010410 2010010506 2015010649 2015010722 2015010812 2015010999 2015011023 数据的含义是：2010012325表示在2010年01月23日的气温为25度。
建表、导入数据：
create table tempertrue(data string); load data local inpath &amp;#34;/data/soft/hive-3.2.1/mydata/tempertrue.txt&amp;#34; into table tempertrue; ※ 1.2 求每一年最高气温的那一天以及温度 首先，先创建一个临时视图，把data分割日期和温度两个字段。
create view temp as select substr(data, 1, 8) as ttime, substr(data, 9) as tep from tempertrue; 利用开窗函数、substr函数对data分割后分组并排序：</description>
    </item>
    
    <item>
      <title>请为Hive开扇窗</title>
      <link>https://niub.link/posts/hive-window-func/</link>
      <pubDate>Sat, 03 Oct 2020 21:01:25 +0800</pubDate>
      
      <guid>https://niub.link/posts/hive-window-func/</guid>
      <description>一、Hive中的开窗函数 1.1 关于开窗函数 什么是开窗函数？
回答这个问题之前先要了解一下什么是聚合函数。聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。再说一遍，聚合函数是SQL的基本函数，其功能是对一组值执行计算，并返回单个值。
常见的聚合函数有：sum()，count()，max()，min()， avg()等，这些聚合函数通常与group by 子句连用，除了count以外，聚合函数忽略空值；
上面有说到，聚合函数只返回单个值，而开窗函数则可为窗口中的每行都返回一个值。更简单的理解就是，对查询的结果多出一列或者多列，列中可以是聚合值也可以试排序值。
一般地，开窗函数也叫分析函数，有两类：聚合开窗函数、排序开窗函数。
另外：
 SQL标准运行将所有的聚合函数用作开窗函数，用OVER关键字区分开窗函数和聚合函数。 聚合函数每组只返回一个值，开窗函数每组（每个窗口）可返回多个值。（上面也有说到过为每行都返回一个值）  1.2 举个不太熟栗子 [root@hadoop200m mydata]# more student_score.data 1 zs1 chinese 80 2 zs1 math 90 3 zs1 english 89 4 zs2 chinese 60 5 zs2 math 75 6 zs2 english 80 7 zs3 chinese 79 8 zs3 math 83 9 zs3 english 72 10 zs4 chinese 90 11 zs4 math 76 12 zs4 english 80 13 zs5 chinese 98 14 zs5 math 80 15 zs5 english 70 select * from student_score; +-------------------+---------------------+--------------------+----------------------+ | student_score.</description>
    </item>
    
    <item>
      <title>浅谈SQL语句的执行顺序</title>
      <link>https://niub.link/posts/sql-execution-sequence/</link>
      <pubDate>Fri, 02 Oct 2020 19:10:59 +0800</pubDate>
      
      <guid>https://niub.link/posts/sql-execution-sequence/</guid>
      <description>浅谈SQL语句的执行顺序 一、SQL语句执行顺序解析 SQL语句和编程语言的语句有很大的不同，有一点原因在于SQL并不一定是按照你写的SQL语句顺序执行的。因此在写SQL语句的时候很容易出现问题，最主要的问题还是记不住SQL命令，死记硬背效果好像也不是很好。
需要知道的是，在SQL语句执行的过程中，都会产生一个虚拟表，用来保存SQL语句的执行结果。这些虚拟表对用户来说是透明的，只有最后一步生成的虚拟表才会返回给用户。如果没有再查询中指定某一子句，则将跳过相应的步骤。下面先给出SQL语句的执行顺序，并加以简单的解释。
7) select 8) distinct &amp;lt;select_list&amp;gt; 1) from &amp;lt;left_table&amp;gt; 3) &amp;lt;join_type&amp;gt; join &amp;lt;right_table&amp;gt; 2) on &amp;lt;join_condition&amp;gt; 4) where &amp;lt;where_condition&amp;gt; 5) group by &amp;lt;group_by_list&amp;gt; 6) having &amp;lt;having_condition&amp;gt; 9) order by &amp;lt;order_by_list&amp;gt; 10) limit &amp;lt;limit_number&amp;gt; 1）from：对FROM子句中的左表&amp;lt;left_table&amp;gt;和右表&amp;lt;right_table&amp;gt;执行笛卡儿积（Cartesian product），产生虚拟表VT1。
2）on： 对虚拟表VT1应用ON筛选，只有那些符合&amp;lt;join_condition&amp;gt;的行才被插入虚拟表VT2中。
3）join：如果指定了OUTER JOIN（如LEFT OUTER JOIN、RIGHT OUTERJOIN），那么保留表中未匹配的行作为外部行添加到虚拟表VT2中，产生虚拟表VT3。如果FROM子句包含两个以上表，则对上一个连接生成的结果表VT3和下一个表重复执行步骤1）～步骤3），直到处理完所有的表为止。
 这里出现了两个陌生的名词：“保留表”、“外部行”。
LEFT OUTER JOIN把左表记为保留表，RIGHT OUTER JOIN把右表记为保留表&amp;hellip;
一时半会也解释不清这个东西，我自己懂了就好了，先挖个坑，日后再补上具体数据来做详细解释说明。
 4）where：对虚拟表VT3应用WHERE过滤条件，只有符合&amp;lt;where_condition&amp;gt;的记录才被插入虚拟表VT4中。
5）group by：根据GROUP BY子句中的列，对VT4中的记录进行分组操作，产生VT5。
6）having：对虚拟表VT6应用HAVING过滤器，只有符合&amp;lt;having_condition&amp;gt;的记录才被插入虚拟表VT6中。
7）select：选择指定的列，插入到虚拟表V7中。
 看到没有，select到第7步才被执行，所以千万别人认为写在第一行的就是第一个被执行的。
 8）distinct：去除重复数据，产生虚拟表V8。
9）order by：将虚拟表V8中的记录按照&amp;lt;order_by_list&amp;gt;进行排序操作，产生虚拟表V9。
 ORDER BY 默认是升序排序，如果要指定为降序排序则需要加上 DESC 修饰。</description>
    </item>
    
    <item>
      <title>Hive认识我的第一天</title>
      <link>https://niub.link/posts/hive-meeting/</link>
      <pubDate>Thu, 01 Oct 2020 17:08:58 +0800</pubDate>
      
      <guid>https://niub.link/posts/hive-meeting/</guid>
      <description>一、Hive简介 1.1 什么是Hive Hive官网给出的定义是：“The Apache Hive ™ data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage. A command line tool and JDBC driver are provided to connect users to Hive.”
我粗糙的理解是，Hive是一个类似Hadoop（集群）的客户端，所谓客户端在手天下我有。就好比你拿到了电视的遥控器，想怎么操作电视就怎么操作电视，比如换台。实际上Hive使用的是类似SQL的语句去操作（离线数据分析、数据管理&amp;hellip;）HDFS上的数据，本质是将SQL语句转化成MapReduce作业。
1.2 为什么要使用Hive Hive的本质是将SQL转化成MapReduce作业，那么直接使用MapReduce不就好了，何必转一个弯呢？因为Hive更方便啊，它是遥控器！MapReduce编程模型还是有一定门槛的，代码量多而且只有map和reduce过程，实现复杂的计算逻辑则难度相当之大。
而，Hive能够使得不会编程的数据开发人员也具备操作分析HDFS上数据的能力，只要你SQL写的好、写的妙。
1.3 Hive有什么特点 先说缺点，这样记得更牢固。
首先，慢，而且不是一般的慢。当然这是对少量数据而言，比如查询十多行的数据需要100秒左右的时间，这哪能忍。
其次，Hive不太支持记录级别的增删改操作。注意是不太支持，你要是真想用还是可以用的，只是要选择对应的Hive版本。
最后，Hive不支持事务。它主要是用来做OLAP（联机分析处理）的，而传统数据库是用来做OLTP（联机事务处理）的，这也是它俩的本质区别之一。
优点，我是记不住，正经人谁记某个东西的优点啊。
首先，延展性好。传统SQL能做的它也能做，传统SQL不能做的它还是能做。比如Hive支持自定义函数UDF，开发人员可以根据自己的需求来实现自定义函数。
其次，拥有HDFS的优点。HDFS的优点也算是它的优点，比如横向扩展。比如加机器的时候是不会对Hive造成影响的，连重启服务也不需要。
最后，良好的容错性。这一点是硬凑的，我理解不到这一层。
稍微总结一下：Hive只适合用来做海量数据离线统计分析，也是数据仓库实现常用的技术之一。
二、Hive的架构  用户接口：包括CLI、JDBC等方式（也就是客户端） 元数据MetaStore：Hive通常将元数据信息保存在传统关系型数据库中，如MySQL，但默认是放在Derby数据库中（这种数据库不支持多用户同时访问）。元数据信息包括：库名、表名、表所属的库名、表的列名/分区字段，表的属性（是否为外部表）、表中数据所在的HDFS目录等信息。【由此可见，元数据的重要性不言而喻。】 Driver：包括：解释器、编译器、优化器、执行器。Hive SQL语句从词法分析、语法分析、编译、优化以及查询计划生成，查询计划存储在HDFS上，MapReduce负责调用执行；  解释器：将用户输入的Hive SQL转化成抽象语法树（AST） 编译器：将AST编译成逻辑执行计划 优化器：将逻辑执行计划进行优化 执行器：优化后的逻辑执行计划转换成可以运行的物理执行计划    三、Hive中数据组织方式 3.</description>
    </item>
    
  </channel>
</rss>
